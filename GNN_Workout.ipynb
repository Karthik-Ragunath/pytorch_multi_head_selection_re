{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "694c9833-3401-45fc-a31f-ed4c12355e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d37f3142-68f3-4e42-b5f2-d8cbc6b9b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_matrix = torch.rand(3, 5, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c356d9-a62b-4e08-be74-d297b80a13f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 2, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f633660-9b17-4213-bb18-0b187e40f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_embedding_matrix = torch.rand(3, 5, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "961777f3-0d78-487e-8383-febbaed16ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87035db6-7dc0-4fc0-bdf0-b87fd67696fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[8.1576e-01, 1.6466e-01, 2.2811e-01, 7.3216e-01, 7.2075e-01],\n",
       "          [3.7893e-01, 5.9991e-01, 2.7131e-01, 1.0301e-01, 4.0049e-01]],\n",
       "\n",
       "         [[9.2903e-03, 6.5002e-01, 6.0578e-01, 7.9372e-01, 8.1719e-01],\n",
       "          [7.6813e-01, 9.8997e-01, 9.5251e-01, 7.0109e-01, 5.2622e-01]],\n",
       "\n",
       "         [[4.5722e-02, 9.5708e-02, 8.7601e-01, 5.4069e-01, 1.0572e-01],\n",
       "          [8.3994e-01, 4.5181e-01, 4.5418e-01, 1.0097e-01, 5.4246e-01]],\n",
       "\n",
       "         [[4.0870e-02, 6.3564e-01, 7.0423e-04, 9.3551e-01, 4.0099e-01],\n",
       "          [1.8823e-01, 4.5103e-01, 3.3701e-01, 4.5281e-01, 3.8668e-01]],\n",
       "\n",
       "         [[4.7575e-01, 6.7045e-01, 4.2536e-01, 5.9260e-02, 2.7956e-01],\n",
       "          [6.8762e-01, 8.5209e-01, 3.2162e-01, 4.6883e-01, 5.9957e-01]]],\n",
       "\n",
       "\n",
       "        [[[4.3056e-01, 5.7011e-01, 7.5427e-01, 5.6362e-01, 9.8281e-01],\n",
       "          [8.5284e-01, 8.6827e-01, 9.2796e-01, 2.2699e-01, 6.9609e-01]],\n",
       "\n",
       "         [[1.2906e-02, 6.5012e-01, 2.3826e-01, 5.4148e-01, 4.6318e-02],\n",
       "          [1.2509e-02, 7.8693e-01, 3.1266e-01, 8.9607e-01, 3.7491e-01]],\n",
       "\n",
       "         [[5.3533e-01, 7.4911e-01, 7.6548e-01, 5.2413e-01, 3.9588e-01],\n",
       "          [2.7205e-01, 2.1075e-02, 9.6544e-01, 6.5816e-01, 1.6730e-01]],\n",
       "\n",
       "         [[5.3685e-01, 9.6534e-01, 8.8280e-01, 6.2018e-01, 4.3664e-01],\n",
       "          [7.0694e-01, 4.9365e-02, 5.5163e-01, 5.5823e-01, 7.4954e-01]],\n",
       "\n",
       "         [[5.3900e-01, 6.4417e-01, 6.4628e-01, 1.2660e-01, 8.8018e-01],\n",
       "          [8.3684e-01, 3.2804e-01, 7.1186e-01, 5.5177e-01, 6.7068e-01]]],\n",
       "\n",
       "\n",
       "        [[[6.0354e-01, 5.6839e-01, 7.6581e-01, 9.3452e-02, 1.6101e-01],\n",
       "          [8.8357e-01, 3.6640e-02, 5.7288e-01, 8.7966e-01, 2.0509e-02]],\n",
       "\n",
       "         [[7.0455e-02, 9.7967e-01, 8.5984e-01, 9.6823e-01, 9.2151e-01],\n",
       "          [8.5494e-01, 8.8902e-01, 3.7851e-01, 5.0988e-01, 1.8660e-01]],\n",
       "\n",
       "         [[3.0629e-01, 8.6170e-01, 7.7934e-01, 7.0792e-01, 6.9565e-01],\n",
       "          [5.1370e-01, 1.0208e-01, 8.3659e-01, 6.8949e-01, 2.2828e-01]],\n",
       "\n",
       "         [[2.9236e-01, 7.1343e-01, 3.3057e-01, 9.6425e-01, 4.9287e-01],\n",
       "          [4.8735e-01, 8.8750e-01, 6.3169e-01, 9.1774e-01, 4.8659e-01]],\n",
       "\n",
       "         [[2.3446e-01, 9.2031e-01, 8.9890e-01, 5.4271e-01, 7.5942e-01],\n",
       "          [4.0572e-01, 3.9043e-01, 6.2878e-01, 1.7074e-01, 1.9310e-01]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c65daebc-f5ec-4cfe-85e6-918239a05ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_matrix_sample = torch.rand(4, 2, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e26e6ae-a422-4ac2-82df-5e5c810cb0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_matrix_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "507c2dea-e323-4401-acdc-1920abe5c7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[7.9426e-01, 2.1193e-01],\n",
       "          [6.5124e-01, 9.3037e-04],\n",
       "          [8.6068e-01, 4.5537e-01]],\n",
       "\n",
       "         [[3.4735e-02, 4.3432e-01],\n",
       "          [7.8259e-01, 5.1166e-02],\n",
       "          [7.6699e-01, 9.3758e-01]]],\n",
       "\n",
       "\n",
       "        [[[8.3720e-01, 7.9063e-01],\n",
       "          [8.0807e-01, 8.6869e-01],\n",
       "          [1.6721e-01, 1.2870e-01]],\n",
       "\n",
       "         [[5.4333e-01, 1.1210e-01],\n",
       "          [9.5634e-01, 1.8790e-01],\n",
       "          [3.3330e-02, 1.6191e-01]]],\n",
       "\n",
       "\n",
       "        [[[2.2553e-01, 5.4298e-01],\n",
       "          [2.8348e-01, 7.2627e-01],\n",
       "          [7.3465e-01, 5.6206e-01]],\n",
       "\n",
       "         [[6.8808e-01, 7.6280e-01],\n",
       "          [8.6816e-02, 5.8671e-01],\n",
       "          [8.0232e-01, 6.8851e-01]]],\n",
       "\n",
       "\n",
       "        [[[6.2312e-01, 5.6335e-01],\n",
       "          [7.8442e-01, 2.9794e-01],\n",
       "          [7.3646e-01, 2.0555e-01]],\n",
       "\n",
       "         [[1.9341e-01, 3.5527e-01],\n",
       "          [4.2862e-01, 5.8753e-01],\n",
       "          [3.5010e-01, 5.5785e-03]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_matrix_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cfc7770-3138-4a27-b5cd-b28137af1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9dd52a3-c175-4b2a-972a-75b1a7c29070",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = 7\n",
    "output_features = 3\n",
    "gcn_conv1 = nn.GCNConv(input_features, output_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb4a468e-552f-4134-b5a5-2da8b4a699dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNConv(7, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f6438ab-09aa-431b-867f-415a3897af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[7.9426e-01, 2.1193e-01],\n",
      "         [6.5124e-01, 9.3037e-04],\n",
      "         [8.6068e-01, 4.5537e-01]],\n",
      "\n",
      "        [[3.4735e-02, 4.3432e-01],\n",
      "         [7.8259e-01, 5.1166e-02],\n",
      "         [7.6699e-01, 9.3758e-01]]])\n",
      "tensor([[[0.8372, 0.7906],\n",
      "         [0.8081, 0.8687],\n",
      "         [0.1672, 0.1287]],\n",
      "\n",
      "        [[0.5433, 0.1121],\n",
      "         [0.9563, 0.1879],\n",
      "         [0.0333, 0.1619]]])\n",
      "tensor([[[0.2255, 0.5430],\n",
      "         [0.2835, 0.7263],\n",
      "         [0.7347, 0.5621]],\n",
      "\n",
      "        [[0.6881, 0.7628],\n",
      "         [0.0868, 0.5867],\n",
      "         [0.8023, 0.6885]]])\n",
      "tensor([[[0.6231, 0.5633],\n",
      "         [0.7844, 0.2979],\n",
      "         [0.7365, 0.2055]],\n",
      "\n",
      "        [[0.1934, 0.3553],\n",
      "         [0.4286, 0.5875],\n",
      "         [0.3501, 0.0056]]])\n"
     ]
    }
   ],
   "source": [
    "for r_m in random_matrix_sample:\n",
    "    print(r_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2e81ff9-95b6-4485-a3e0-bd26a73a8943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_matrix_sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bfabb1a-195b-4849-bc8e-f69fdfb89e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_matrix_sample_axis_swapped = torch.swapaxes(random_matrix_sample, -1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0663b33a-01e1-4ab4-b780-bc981ccd1a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[7.9426e-01, 6.5124e-01, 8.6068e-01],\n",
       "          [2.1193e-01, 9.3037e-04, 4.5537e-01]],\n",
       "\n",
       "         [[3.4735e-02, 7.8259e-01, 7.6699e-01],\n",
       "          [4.3432e-01, 5.1166e-02, 9.3758e-01]]],\n",
       "\n",
       "\n",
       "        [[[8.3720e-01, 8.0807e-01, 1.6721e-01],\n",
       "          [7.9063e-01, 8.6869e-01, 1.2870e-01]],\n",
       "\n",
       "         [[5.4333e-01, 9.5634e-01, 3.3330e-02],\n",
       "          [1.1210e-01, 1.8790e-01, 1.6191e-01]]],\n",
       "\n",
       "\n",
       "        [[[2.2553e-01, 2.8348e-01, 7.3465e-01],\n",
       "          [5.4298e-01, 7.2627e-01, 5.6206e-01]],\n",
       "\n",
       "         [[6.8808e-01, 8.6816e-02, 8.0232e-01],\n",
       "          [7.6280e-01, 5.8671e-01, 6.8851e-01]]],\n",
       "\n",
       "\n",
       "        [[[6.2312e-01, 7.8442e-01, 7.3646e-01],\n",
       "          [5.6335e-01, 2.9794e-01, 2.0555e-01]],\n",
       "\n",
       "         [[1.9341e-01, 4.2862e-01, 3.5010e-01],\n",
       "          [3.5527e-01, 5.8753e-01, 5.5785e-03]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_matrix_sample_axis_swapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4e52d7c-d179-4efd-9872-9633ec874a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 2, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_matrix_sample_axis_swapped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a041fd6a-1762-43b2-9f8f-caef865a0c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_source_dest_tensors = torch.tensor([[[],[]]])\n",
    "stacked_weight_tensors = torch.tensor([[]])\n",
    "for r_m in range(len(random_matrix_sample_axis_swapped)):\n",
    "    source_dest_tensor = torch.tensor([[],[]])\n",
    "    weight_tensor = torch.tensor([])\n",
    "    for source in range(len(random_matrix_sample_axis_swapped[r_m])):\n",
    "        for destination in range(len(random_matrix_sample_axis_swapped[r_m][source])):\n",
    "            for relation in range(len(random_matrix_sample_axis_swapped[r_m][source][destination])):\n",
    "                source_dest_tensor = torch.cat((source_dest_tensor, torch.reshape(torch.tensor([source,destination]), (2,1))), 1)\n",
    "                weight_tensor = torch.cat((weight_tensor, torch.tensor([random_matrix_sample_axis_swapped[r_m][source][destination][relation]])), 0)\n",
    "    source_dest_tensor_unsqueezed = torch.unsqueeze(source_dest_tensor, dim=0)\n",
    "    weight_tensor_unsqueezed = torch.unsqueeze(weight_tensor, dim=0)\n",
    "    if not stacked_source_dest_tensors.numel():\n",
    "        stacked_source_dest_tensors = source_dest_tensor_unsqueezed\n",
    "        stacked_weight_tensors = weight_tensor_unsqueezed\n",
    "    else:\n",
    "        stacked_source_dest_tensors = torch.cat((stacked_source_dest_tensors, source_dest_tensor_unsqueezed), dim=0)\n",
    "        stacked_weight_tensors = torch.cat((stacked_weight_tensors, weight_tensor_unsqueezed), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f75a2487-7f91-4272-9477-fd8259de7105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "a = source_dest_tensor_unsqueezed.grad\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "abb49ad6-4ebf-4b06-9843-d90c75018e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_source_dest_long_tensors = stacked_source_dest_tensors.to(dtype=torch.long, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e74cf962-6e5a-466c-93ab-35646e7aa010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_source_dest_long_tensors = stacked_source_dest_tensors.to(dtype=torch.long)\n",
    "stacked_source_dest_long_tensors = stacked_source_dest_tensors.to(dtype=torch.int64)\n",
    "stacked_weight_tensors = stacked_weight_tensors.to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a25bafc-3348-4c3b-b679-1f2c6283c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_embedding = torch.rand(4, 2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81264b58-9fa3-40a8-b240-076984498091",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_embedding = random_embedding.to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7fa851f-69db-460d-b534-b7a257b35b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_weight_tensors = stacked_weight_tensors.to(device='cuda')\n",
    "# random_embedding = random_embedding.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d77af684-fa2d-4c8e-8ca2-96fb4018e7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 12])\n"
     ]
    }
   ],
   "source": [
    "print(stacked_source_dest_long_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67be1216-d41c-4075-bf7e-16f6d7595a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 12])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_weight_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32452d0c-3489-4b83-b8c6-a4d0b57afb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0153, 0.4764, 0.5792, 0.9074, 0.4270, 0.0366],\n",
       "         [0.4455, 0.6412, 0.7973, 0.4140, 0.5115, 0.6130]],\n",
       "\n",
       "        [[0.5805, 0.5897, 0.8438, 0.5232, 0.8937, 0.2336],\n",
       "         [0.5762, 0.8037, 0.4904, 0.4823, 0.6909, 0.9418]],\n",
       "\n",
       "        [[0.9925, 0.7488, 0.2942, 0.8792, 0.2319, 0.4086],\n",
       "         [0.2910, 0.5968, 0.0894, 0.6777, 0.9551, 0.2706]],\n",
       "\n",
       "        [[0.8708, 0.0733, 0.2123, 0.2315, 0.2924, 0.6151],\n",
       "         [0.1349, 0.1676, 0.9906, 0.4050, 0.0171, 0.9036]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf175564-8a9c-4530-9be1-4fd504bb8919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_source_dest_tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c800f48d-03ff-4d34-b161-f944d92ae544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stacked_source_dest_tensors[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd34abc2-5fb0-44ac-990a-abf3c46aac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0573e7bf-7e42-4b41-ba8b-ffd5f715d72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_embedding[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19cf284f-f9a7-45db-9bf9-bb9294873896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_weight_tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cc5fac9-d5db-4f8e-9233-faff63b4129e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.9426e-01, 6.5124e-01, 8.6068e-01, 2.1193e-01, 9.3037e-04, 4.5537e-01,\n",
       "        3.4735e-02, 7.8259e-01, 7.6699e-01, 4.3432e-01, 5.1166e-02, 9.3758e-01])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_weight_tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab37c2fc-3fa6-4f57-97ab-51b90e98e0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_embedding[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c0b608d-c341-455a-a583-2d18adfd61ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0153, 0.4764, 0.5792, 0.9074, 0.4270, 0.0366],\n",
       "        [0.4455, 0.6412, 0.7973, 0.4140, 0.5115, 0.6130]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03e33376-c9c3-4430-bf87-b5faac9458b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_source_dest_long_tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45852526-2ea2-4bcf-ac90-5da14ae0784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95dbc04e-1ca3-40a2-947a-c44b5f3da799",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=random_embedding[0], edge_index=stacked_source_dest_long_tensors[0], edge_weights=stacked_weight_tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eedc263c-3cc2-48ec-9968-a734cb0d0f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c11a976-698c-4711-b509-d960349fa872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0070150-ef46-4b17-92d0-9b5a0f2c33a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.9426e-01, 6.5124e-01, 8.6068e-01, 2.1193e-01, 9.3037e-04, 4.5537e-01,\n",
       "        3.4735e-02, 7.8259e-01, 7.6699e-01, 4.3432e-01, 5.1166e-02, 9.3758e-01])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eacbc921-33cd-4f03-adfd-d80e6b8c9ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.has_self_loops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fed8c6e-06b3-41bd-b509-aabceb6a7845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5428b766-88f0-4fb1-a8d6-5322d5ca9ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2, 6], edge_index=[2, 12], edge_weights=[12])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75bd946a-07ff-4aec-a757-b28e27920569",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_conv = nn.GCNConv(in_channels=data.num_features, out_channels=5, add_self_loops=False)\n",
    "# gcn_conv = nn.GCNConv(in_channels=data.num_features, out_channels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d80de90-3a4d-470b-9ffe-c7c769fc287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gcn_conv(x = random_embedding[0], edge_index=data.edge_index, edge_weight=data.edge_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4852328b-a42a-402d-907f-0adecb270050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2695, -0.8779, -0.8333,  1.4023, -0.9468],\n",
       "        [ 0.1619, -0.6241, -0.6956,  1.2191, -0.8215]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49e8858b-f0e2-4ad6-9970-585dea2feed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea0eb265-1031-4a58-8ff0-fed699d14327",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_source_dest_tensors = torch.tensor([[[],[]]])\n",
    "stacked_weight_tensors = torch.tensor([[]])\n",
    "for r_m in range(len(random_matrix_sample_axis_swapped)):\n",
    "    source_dest_tensor = torch.tensor([[],[]])\n",
    "    weight_tensor = torch.tensor([])\n",
    "    for source in range(len(random_matrix_sample_axis_swapped[r_m])):\n",
    "        for destination in range(len(random_matrix_sample_axis_swapped[r_m][source])):\n",
    "            for relation in range(len(random_matrix_sample_axis_swapped[r_m][source][destination])):\n",
    "                source_dest_tensor = torch.cat((source_dest_tensor, torch.reshape(torch.tensor([source,destination]), (2,1))), 1)\n",
    "                weight_tensor = torch.cat((weight_tensor, torch.tensor([random_matrix_sample_axis_swapped[r_m][source][destination][relation]])), 0)\n",
    "    source_dest_tensor_unsqueezed = torch.unsqueeze(source_dest_tensor, dim=0)\n",
    "    weight_tensor_unsqueezed = torch.unsqueeze(weight_tensor, dim=0)\n",
    "    if not stacked_source_dest_tensors.numel():\n",
    "        stacked_source_dest_tensors = source_dest_tensor_unsqueezed\n",
    "        stacked_weight_tensors = weight_tensor_unsqueezed\n",
    "    else:\n",
    "        stacked_source_dest_tensors = torch.cat((stacked_source_dest_tensors, source_dest_tensor_unsqueezed), dim=0)\n",
    "        stacked_weight_tensors = torch.cat((stacked_weight_tensors, weight_tensor_unsqueezed), dim=0)\n",
    "\n",
    "stacked_source_dest_long_tensors = stacked_source_dest_tensors.to(dtype=torch.int64)\n",
    "stacked_weight_tensors = stacked_weight_tensors.to(dtype=torch.float32)\n",
    "random_embedding = torch.rand(4, 2, 6)\n",
    "random_embedding = random_embedding.to(dtype=torch.float32)\n",
    "\n",
    "dataset_list = []\n",
    "for index in range(len(stacked_source_dest_long_tensors)):\n",
    "    data = Data(x=random_embedding[index], edge_index=stacked_source_dest_long_tensors[index], edge_weights=stacked_weight_tensors[index])\n",
    "    dataset_list.append(data)\n",
    "batched_dataset = DataLoader(dataset_list, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9107a0fd-390d-4c62-8eef-b7192b9c355d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric.loader.dataloader.DataLoader at 0x7f6c0826ce80>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "716b8119-f730-4cb3-90ea-916b75439508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[4, 6], edge_index=[2, 24], edge_weights=[24], batch=[4], ptr=[3])\n",
      "DataBatch(x=[4, 6], edge_index=[2, 24], edge_weights=[24], batch=[4], ptr=[3])\n"
     ]
    }
   ],
   "source": [
    "for dataset in batched_dataset:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c6f2b463-d750-4a7b-9cbe-264387f53c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 -1 -1\n",
      "torch.Size([4, 5])\n",
      "-1 -1 -1\n",
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "for dataset in batched_dataset:\n",
    "    print(dataset.x.get_device(), dataset.edge_index.get_device(), dataset.edge_weights.get_device())\n",
    "    x = gcn_conv(x = dataset.x, edge_index=dataset.edge_index, edge_weight=dataset.edge_weights)\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "081346cf-2dd9-4b19-ae1a-f0b9c1f4775d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0421, -0.3052, -1.3759,  1.4789, -1.3269],\n",
      "        [ 0.0774, -0.1094, -1.1422,  0.9927, -1.1534],\n",
      "        [-0.0050, -0.7100, -0.8903,  1.6072, -0.8738],\n",
      "        [-0.0744, -0.5218, -0.7591,  1.3438, -0.6906]], grad_fn=<AddBackward0>) tensor([[[ 0.0421, -0.3052, -1.3759,  1.4789, -1.3269],\n",
      "         [ 0.0774, -0.1094, -1.1422,  0.9927, -1.1534]],\n",
      "\n",
      "        [[-0.0050, -0.7100, -0.8903,  1.6072, -0.8738],\n",
      "         [-0.0744, -0.5218, -0.7591,  1.3438, -0.6906]]],\n",
      "       grad_fn=<ReshapeAliasBackward0>) torch.Size([2, 2, 5]) torch.Size([2, 2, 5])\n",
      "tensor([[-0.0200, -0.3361, -0.9285,  1.1167, -0.8154],\n",
      "        [-0.0432, -0.3982, -1.0855,  1.3312, -0.9318],\n",
      "        [-0.1077, -0.4778, -0.9929,  1.3191, -0.6882],\n",
      "        [-0.0584, -0.3743, -0.7823,  1.0327, -0.5894]], grad_fn=<AddBackward0>) tensor([[[-0.0200, -0.3361, -0.9285,  1.1167, -0.8154],\n",
      "         [-0.0432, -0.3982, -1.0855,  1.3312, -0.9318]],\n",
      "\n",
      "        [[-0.1077, -0.4778, -0.9929,  1.3191, -0.6882],\n",
      "         [-0.0584, -0.3743, -0.7823,  1.0327, -0.5894]]],\n",
      "       grad_fn=<ReshapeAliasBackward0>) torch.Size([2, 2, 5]) torch.Size([4, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "# concatenated_batches = torch.empty((2,2,5))\n",
    "concatenated_batches = torch.tensor([])\n",
    "for dataset in batched_dataset:\n",
    "    x = gcn_conv(x = dataset.x, edge_index=dataset.edge_index, edge_weight=dataset.edge_weights)\n",
    "    y = torch.reshape(x, (-1, 2, 5))\n",
    "    if not concatenated_batches.numel():\n",
    "        concatenated_batches = y\n",
    "    else:\n",
    "        concatenated_batches = torch.cat((concatenated_batches, y), dim=0)\n",
    "    print(x, y, y.shape, concatenated_batches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f34692b-9af1-4aef-85a8-fdb03f4e6151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0421, -0.3052, -1.3759,  1.4789, -1.3269],\n",
      "        [ 0.0774, -0.1094, -1.1422,  0.9927, -1.1534]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.0050, -0.7100, -0.8903,  1.6072, -0.8738],\n",
      "        [-0.0744, -0.5218, -0.7591,  1.3438, -0.6906]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.0200, -0.3361, -0.9285,  1.1167, -0.8154],\n",
      "        [-0.0432, -0.3982, -1.0855,  1.3312, -0.9318]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.1077, -0.4778, -0.9929,  1.3191, -0.6882],\n",
      "        [-0.0584, -0.3743, -0.7823,  1.0327, -0.5894]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(random_embedding)):\n",
    "    data = Data(x=random_embedding[i], edge_index=stacked_source_dest_long_tensors[i], edge_weights=stacked_weight_tensors[i])\n",
    "    x = gcn_conv(x = data.x, edge_index=data.edge_index, edge_weight=data.edge_weights)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b8101784-19d3-4efc-af9c-6925b0b56560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for dataset in batched_dataset:\n",
    "    dataset.to(device='cuda')\n",
    "    print(dataset.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c547aa3f-27e1-4aba-9a2f-5bbce1b3b0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_embedding[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a36e38ef-a24e-4ad4-abc5-0d436e885e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 5])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f90a31b8-fd40-4b6b-8a5b-fd36db2babee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(concatenated_batches.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5ec2bf6-e9dd-45f9-a6e6-b2158ab77a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(concatenated_batches)\n",
    "seq_len = len(concatenated_batches[0])\n",
    "num_features = len(concatenated_batches[0][0])\n",
    "\n",
    "num_layers = 1\n",
    "num_directions = 2\n",
    "output_size = len(concatenated_batches[0][0])\n",
    "\n",
    "input = concatenated_batches\n",
    "hidden = torch.randn(num_layers * num_directions, batch_size, output_size)\n",
    "cell_state = torch.randn(num_layers * num_directions, batch_size, output_size)\n",
    "cell = torch.nn.LSTM(input_size = num_features, hidden_size = output_size, batch_first = True, num_layers=1, bidirectional=True)\n",
    "\n",
    "out, hidden = cell(input, (hidden, cell_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "49a57ba5-e2c8-41fc-94fe-d7ff97eec515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn = nn.LSTM(10, 20, 2)\n",
    "# input = torch.randn(5, 3, 10)\n",
    "# h0 = torch.randn(2, 3, 20)\n",
    "# c0 = torch.randn(2, 3, 20)\n",
    "# output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1e0ba8e5-dc54-4d35-a0f5-6fe94c6c13fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 10])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c93b9ab0-366d-43f9-a24e-7940004de286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0701, -0.0984, -0.1751, -0.1928, -0.1568],\n",
       "          [-0.1548, -0.2780,  0.2074, -0.2525, -0.0399],\n",
       "          [-0.0371,  0.3200,  0.4437, -0.2267, -0.2245],\n",
       "          [-0.0351,  0.3551, -0.2270, -0.2853, -0.2405]],\n",
       " \n",
       "         [[-0.1288,  0.0036, -0.0282,  0.0419,  0.2395],\n",
       "          [-0.1016,  0.1106, -0.0242,  0.0443,  0.1908],\n",
       "          [-0.1136, -0.0025, -0.0601, -0.0023,  0.1708],\n",
       "          [-0.1062, -0.1079,  0.0220,  0.0560,  0.2136]]],\n",
       "        grad_fn=<StackBackward0>),\n",
       " tensor([[[-0.1788, -0.1770, -0.4030, -0.3803, -0.3624],\n",
       "          [-0.5810, -0.4729,  0.3874, -0.4670, -0.0994],\n",
       "          [-0.1013,  0.5025,  1.5445, -0.4340, -0.5234],\n",
       "          [-0.0770,  0.6216, -0.5805, -0.4941, -0.5362]],\n",
       " \n",
       "         [[-0.2687,  0.0105, -0.1053,  0.2740,  0.5939],\n",
       "          [-0.1896,  0.3604, -0.1150,  0.2396,  0.4901],\n",
       "          [-0.2155, -0.0065, -0.2349, -0.0115,  0.4487],\n",
       "          [-0.2116, -0.3008,  0.0894,  0.3007,  0.6301]]],\n",
       "        grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "88a3c8e0-9821-4123-a6d8-3ffbc3dcbbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a145443-7ca5-464d-9402-628fa8ba2414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0083,  0.0191, -0.4402, -0.1113, -0.0858, -0.1288,  0.0036,\n",
       "          -0.0282,  0.0419,  0.2395],\n",
       "         [-0.0701, -0.0984, -0.1751, -0.1928, -0.1568, -0.2036,  0.0543,\n",
       "          -0.0382,  0.0146,  0.2814]],\n",
       "\n",
       "        [[-0.1020, -0.1818,  0.1826, -0.1636,  0.1667, -0.1016,  0.1106,\n",
       "          -0.0242,  0.0443,  0.1908],\n",
       "         [-0.1548, -0.2780,  0.2074, -0.2525, -0.0399, -0.1215,  0.2198,\n",
       "          -0.0546,  0.0047,  0.1573]],\n",
       "\n",
       "        [[ 0.1607,  0.4260,  0.3324, -0.1557, -0.2084, -0.1136, -0.0025,\n",
       "          -0.0601, -0.0023,  0.1708],\n",
       "         [-0.0371,  0.3200,  0.4437, -0.2267, -0.2245, -0.0868,  0.0224,\n",
       "          -0.1330, -0.0610,  0.0519]],\n",
       "\n",
       "        [[ 0.1804,  0.5603, -0.1768, -0.3297, -0.2493, -0.1062, -0.1079,\n",
       "           0.0220,  0.0560,  0.2136],\n",
       "         [-0.0351,  0.3551, -0.2270, -0.2853, -0.2405, -0.1471, -0.1588,\n",
       "           0.1253,  0.0114,  0.3071]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "41d97cf5-406b-43fa-9ffd-828075d39ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_output = out[:,-1,:]\n",
    "actual_output_unsqueezed = actual_output.unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3047b366-edc6-4d3b-8e95-1685dceb76ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8daefc0a-2aaa-41cd-9f2f-516d8e1677b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 10])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_output_unsqueezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a46581-aaf1-438f-a960-c2f4491331bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac389d-94c9-4561-85d6-c50d2354661e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fdb7c7-b792-44af-96e5-0db684bcf637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373fb8c0-7a20-4c56-8858-84b485c813a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5acdb7-0804-4cbd-bb59-839d983054a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "503fdcdc-ba7d-48d2-917c-846f4cc8b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Rough ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e93381f-9a2d-4e7a-a38d-b541c7c34d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.empty((2,3), dtype=torch.int32, device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ffa0741-e55f-4591-87a3-7dc0a5f7005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3, 4)\n",
    "b = torch.zeros(1, 4)\n",
    "\n",
    "idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47d1c23c-707e-4073-99e1-07fbd7da2759",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.cat([a[:idx], b, a[idx:]], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1afe84f5-548f-4437-ae07-e240f10b4f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3400, 0.8049, 0.7360, 0.5542],\n",
       "        [0.0220, 0.6208, 0.7575, 0.9252],\n",
       "        [0.1766, 0.6195, 0.2240, 0.5277]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "267dd6cf-76c5-4932-b460-0e91d83d15b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00c21a94-83b4-45b0-929c-d679e77a9fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3400, 0.8049, 0.7360, 0.5542],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0220, 0.6208, 0.7575, 0.9252],\n",
       "        [0.1766, 0.6195, 0.2240, 0.5277]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10f5483a-352c-4175-ae39-e3dcbd029173",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.cat([a[:idx], b], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f297c6f7-8ea9-4cdf-82cd-e2d32e0ef4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3400, 0.8049, 0.7360, 0.5542],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a009ea6-893e-481d-926e-0997f5d59350",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.cat([a[0], torch.tensor([1])], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc35b8b3-d05f-4d64-9a96-31ee59c96bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d9ed9b0-b81b-4737-8c06-e74d873a1382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff3e7505-f1bc-4a12-bf5f-e1c2c83c9c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3400, 0.8049, 0.7360, 0.5542, 1.0000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3b862ac-3dfc-4200-a69c-934a42813e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3400, 0.8049, 0.7360, 0.5542],\n",
       "        [0.0220, 0.6208, 0.7575, 0.9252],\n",
       "        [0.1766, 0.6195, 0.2240, 0.5277]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83fc3ffa-9188-4d1f-8fb5-ea8051199035",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dest_tensor = torch.tensor([[]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc4626fc-5c1f-4027-bf0e-b82756dbf156",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.cat((a, torch.reshape(torch.tensor([1,2,3]), (3,1))), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c236179-b7f3-42c0-9d0f-b1421558515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0, 4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13f7d652-68cc-4ad0-9350-f35c780b3617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c327a93-48f7-4e46-8a6d-170571663571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05c7c59f-bbb0-44e3-9ebc-409437ca1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1de71ebd-10ec-411e-9db6-642a6f832187",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.cat((h, torch.tensor([0])), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f8569d0-a33e-4181-b337-1021ae35656b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca38deb0-3044-4b10-a6b0-94eae463bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = torch.tensor([])\n",
    "tensor_2 = torch.ones(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f9cd1295-0f28-4280-b315-c865e13ffee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_source_dest_tensors = torch.tensor([[],[]])\n",
    "stacked_source_dest_tensors.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "34ca85ae-8f19-450a-897e-8716c8e3c94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f87e0228-ab65-4af3-8a64-1e65f5ee9c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(tensor_2, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1dad8891-cc18-4ca9-8287-19fd5cee9177",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4ce63aa9-e70e-48cf-b8a9-e75664c86b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d3fc7525-5868-41e3-a149-73b0110b4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2aed4c3c-3d51-4b1c-bdeb-4e8c7ef6a110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de6e2cf-c3f2-4f5f-8d87-4d7174d4d5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
      "Extracting /tmp/ENZYMES/ENZYMES/ENZYMES.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "tu_dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ea8aa1-e175-432d-ab8d-180c8ba6f9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENZYMES(600)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ee7d4-df10-4548-9693-9cd9b9eadf12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
